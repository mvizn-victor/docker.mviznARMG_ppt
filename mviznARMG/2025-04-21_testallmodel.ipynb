{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4af838-d11d-47ff-b0b0-100addd4ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9aa452",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'vcutils/taggerhelperfun.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f67401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'vcutils/C__flaskdisplay.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d05e979f-bba6-4a79-a499-c50b5421cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd=C__flaskdisplay('001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d90a3bf6-2fbe-4fbf-9950-9941fdf1281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_hncdstop=YOLO('HNCDS/weights/HNCDS.weights')\n",
    "yolo_hncdsside=YOLO('HNCDS/weights/HNCDSside.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb32dc3f-c37f-4f6e-9f0d-bcbc9551b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception=Inception('HNCDS/weights/HNCDS.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38f560d3-2b57-4ec7-8936-6615ba66f2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('p', 0.8622997)\n",
      "('p', 0.8564898)\n",
      "('p', 0.76347184)\n",
      "('p', 0.9538895)\n",
      "('n', 0.90462136)\n"
     ]
    }
   ],
   "source": [
    "progress=Progress()\n",
    "cap=cv2.VideoCapture('HNCDS/sample/2.mp4')\n",
    "i=0\n",
    "while 1:\n",
    "    ret,frame=cap.read()\n",
    "    if not ret:break\n",
    "    i+=1\n",
    "    if i%10!=0:continue        \n",
    "    framecopy=frame.copy()\n",
    "    res=yolo_hncdsside.infer(frame)\n",
    "    zipres=list(x for x in zip(*res))\n",
    "    for label,prob,rect in zipres:\n",
    "        x1,y1,x2,y2=C__rect(rect).x1y1x2y2()\n",
    "        if label=='p':\n",
    "            progress.print(inception.infer(frame[y1:y2,x1:x2]))\n",
    "    Tagger.yolodrawres(frame,list(zip(*zipres)),yolo_hncdsside.classes)\n",
    "    fd.imswk(frame,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a826406d-e13b-4d6a-b638-7c1295533196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n', 0.5962067)\n",
      "('n', 0.5994929)\n",
      "('p', 0.8959725)\n",
      "('p', 0.5771009)\n",
      "('p', 0.9430079)\n"
     ]
    }
   ],
   "source": [
    "progress=Progress()\n",
    "cap=cv2.VideoCapture('HNCDS/sample/1.mp4')\n",
    "i=0\n",
    "while 1:\n",
    "    ret,frame=cap.read()\n",
    "    if not ret:break\n",
    "    i+=1\n",
    "    if i%10!=0:continue        \n",
    "    framecopy=frame.copy()\n",
    "    res=yolo_hncdstop.infer(frame)\n",
    "    zipres=list(x for x in zip(*res))\n",
    "    for label,prob,rect in zipres:\n",
    "        x1,y1,x2,y2=C__rect(rect).x1y1x2y2()\n",
    "        if label=='p':\n",
    "            progress.print(inception.infer(frame[y1:y2,x1:x2]))\n",
    "    Tagger.yolodrawres(frame,list(zip(*zipres)),yolo_hncdstop.classes)    \n",
    "    fd.imswk(frame,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c6cc8bf-6bf9-4a27-a2ea-8fa695390995",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_tcdsnp=YOLO('TCDS/weights/TCDSnp.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "896f0793-1ef8-464b-bb4f-259994149734",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      3\u001b[0m     ret,frame\u001b[38;5;241m=\u001b[39mcap\u001b[38;5;241m.\u001b[39mread()    \n\u001b[0;32m----> 4\u001b[0m     \u001b[43mTagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myolodraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43myolo_tcdsnp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     fd\u001b[38;5;241m.\u001b[39mimswk(frame,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/app/vcutils/taggerhelperfun.py:423\u001b[0m, in \u001b[0;36mTagger.yolodraw\u001b[0;34m(im, yolo)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21myolodraw\u001b[39m(im,yolo):\n\u001b[0;32m--> 423\u001b[0m     res\u001b[38;5;241m=\u001b[39m\u001b[43myolo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label,prob,box \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mres):\n\u001b[1;32m    425\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mrectangle(im,box,color\u001b[38;5;241m=\u001b[39mrainbowbgr[yolo\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;241m.\u001b[39mindex(label)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m7\u001b[39m],thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/app/vcutils/helperfun.py:805\u001b[0m, in \u001b[0;36mYOLO.infer\u001b[0;34m(self, frame, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame, CONFIDENCE_THRESHOLD\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, NMS_THRESHOLD\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m):\n\u001b[0;32m--> 805\u001b[0m     classes, scores, boxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIDENCE_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNMS_THRESHOLD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses[geti0(i)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m classes)\n\u001b[1;32m    807\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(geti0(score) \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m scores)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture('TCDS/sample/1.mp4')\n",
    "while 1:\n",
    "    ret,frame=cap.read()    \n",
    "    Tagger.yolodraw(frame,yolo_tcdsnp)\n",
    "    fd.imswk(frame,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c356e5-beec-4367-9575-95a982a6f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskoutcontainer(image0,maskout=True):\n",
    "    from Utils.helper import procimage\n",
    "    r0 = procimage('clpsmaskrcnn',image0)\n",
    "    if 0:visualize.display_instances(\n",
    "                    image0, r0['rois'], r0['masks'], r0['class_ids'],\n",
    "                    VOC_CLASSES, r0['scores'],\n",
    "                    show_bbox=True, show_mask=True,\n",
    "                    title=\"Predictions\")\n",
    "    elif 0:\n",
    "        visualize.display_instances(\n",
    "            image0, r0['rois'], r0['mask'], r0['class'],\n",
    "            VOC_CLASSES, r0['scores'],\n",
    "            show_bbox=True, show_mask=True,\n",
    "            title=\"Predictions\")\n",
    "    newmask=np.zeros(image0.shape[:2],dtype=bool)\n",
    "    classids=r0['class_ids']\n",
    "    for maski in range(len(r0['class_ids'])):\n",
    "        if classids[maski]==1:\n",
    "            mask=r0['masks'][:,:,maski]\n",
    "            for i in range(mask.shape[1]):\n",
    "                try:\n",
    "                    newmask[0:np.max(np.argwhere(mask[:,i]==1))+10,i]=1\n",
    "                except:\n",
    "                    pass\n",
    "    #newmask[:,0:np.min(np.argwhere(newmask),axis=0)[1]]=1\n",
    "    #newmask[:,np.max(np.argwhere(newmask),axis=0)[1]:]=1\n",
    "    newmask[:,np.max(newmask,axis=0)==False]=1\n",
    "    for maski in range(len(r0['class_ids'])):\n",
    "        if classids[maski]!=1:\n",
    "            mask=r0['masks'][:,:,maski]\n",
    "            newmask[mask]=1    \n",
    "    if maskout:\n",
    "        image0[newmask]=0\n",
    "    return newmask\n",
    "\n",
    "def overlaymask(mask,image,alpha=0.5):\n",
    "    overlay = image.copy()\n",
    "    output = image.copy()\n",
    " \n",
    "    # draw a red rectangle surrounding Adrian in the image\n",
    "    # along with the text \"PyImageSearch\" at the top-left\n",
    "    # corner\n",
    "    overlay[mask]=(255,0,0)    \n",
    "    cv2.addWeighted(overlay, alpha, output, 1 - alpha,0, output)\n",
    "    return output\n",
    "l__imf=sorted(glob.glob('CLPS/sample/2020-01-09/15-00-29/raw/t*.jpg'))\n",
    "for imf in l__imf:\n",
    "    im=cv2.imread(imf)\n",
    "    newmask=maskoutcontainer(im, False)\n",
    "    im=overlaymask(newmask,im)\n",
    "    #print(imf,procimage('clpsmaskrcnn',im))\n",
    "    fd.imswk(im,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba61675f-bd1c-490f-aebc-1b945b400a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/04/22 22:14:50] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/hostuser/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/hostuser/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.10/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/home/hostuser/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize PaddleOCR model\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')  # Use English model\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2be3a3d7-487f-4ccb-a48c-14729791df79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['t'], [0.99843836], array([[206,   5, 226, 162]], dtype=int32))\n",
      "[2025/04/22 22:21:32] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.01659989356994629\n",
      "[2025/04/22 22:21:32] ppocr DEBUG: cls num  : 4, elapsed : 0.007981538772583008\n",
      "[2025/04/22 22:21:32] ppocr DEBUG: rec_res num  : 4, elapsed : 0.07406878471374512\n",
      "[[[[[1.0, 0.0], [36.0, 0.0], [36.0, 11.0], [1.0, 11.0]], ('14:32', 0.9057049751281738)], [[[75.0, 31.0], [151.0, 31.0], [151.0, 80.0], [75.0, 80.0]], ('914', 0.9987166523933411)], [[[38.0, 85.0], [186.0, 83.0], [187.0, 111.0], [39.0, 114.0]], ('XD7687S', 0.9636298418045044)]]]\n",
      "HERE\n",
      "Detected Text: 14:32, Confidence: 0.91\n",
      "Detected Text: 914, Confidence: 1.00\n",
      "Detected Text: XD7687S, Confidence: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im=cv2.imread('PMNRS/sample/1.jpg')\n",
    "imcp=im.copy()\n",
    "res=(yolo_hncdstop.infer(im))\n",
    "print(res)\n",
    "for label,prob,rect in zip(*res):\n",
    "    if label=='t':\n",
    "        x1,y1,w,h=rect\n",
    "        x2,y2=x1+w,y1+h\n",
    "        pass\n",
    "imcrop=im[y1:y2,x1:x2]\n",
    "img_rgb = cv2.cvtColor(imcrop, cv2.COLOR_BGR2RGB)\n",
    "#Tagger.yolodrawres(imcp,res,hncdsyolo.classes)\n",
    "#fd.imswk(imcp,1);\n",
    "result = ocr.ocr(img_rgb, cls=True)\n",
    "\n",
    "print(result)        \n",
    "print(\"HERE\")\n",
    "# Display recognized text\n",
    "for line in result[0]:\n",
    "    box, (text, confidence) = line\n",
    "    print(f\"Detected Text: {text}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "# Optional: visualize\n",
    "#image = Image.open(img_path).convert('RGB')\n",
    "boxes = [line[0] for line in result[0]]\n",
    "txts = [line[1][0] for line in result[0]]\n",
    "scores = [line[1][1] for line in result[0]]\n",
    "im_show = draw_ocr(img_rgb, boxes, txts, scores, font_path='fonts/simfang.ttf')\n",
    "im_show = Image.fromarray(im_show)\n",
    "im_show.save('/tmp/result.jpg')\n",
    "imout=cv2.imread('/tmp/result.jpg')\n",
    "fd.imswk(imout,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
